{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4509bc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "from tempfile import TemporaryDirectory\n",
    "import time\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48d03be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Root_dir = \"D:/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)\"\n",
    "train_dir = Root_dir + \"/train\"\n",
    "valid_dir = Root_dir + \"/valid\"\n",
    "test_dir = \"D:/New Plant Diseases Dataset(Augmented)/test\"\n",
    "Diseases_classes = os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "181f4fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = datasets.ImageFolder(os.path.join(Root_dir, 'test'), transform= transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00f4fa45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "class_names = test.classes\n",
    "\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df912608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
    "        \n",
    "# convolution block with BatchNormalization\n",
    "def ConvBlock(in_channels, out_channels, pool=False):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "             nn.BatchNorm2d(out_channels),\n",
    "             nn.ReLU(inplace=True)]\n",
    "    if pool:\n",
    "        layers.append(nn.MaxPool2d(4))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "# resnet architecture \n",
    "class CNN_NeuralNet(ImageClassificationBase):\n",
    "    def __init__(self, in_channels, num_diseases):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = ConvBlock(in_channels, 64)\n",
    "        self.conv2 = ConvBlock(64, 128, pool=True) \n",
    "        self.res1 = nn.Sequential(ConvBlock(128, 128), ConvBlock(128, 128))\n",
    "        \n",
    "        self.conv3 = ConvBlock(128, 256, pool=True) \n",
    "        self.conv4 = ConvBlock(256, 512, pool=True)\n",
    "        \n",
    "        self.res2 = nn.Sequential(ConvBlock(512, 512), ConvBlock(512, 512))\n",
    "        self.classifier = nn.Sequential(nn.MaxPool2d(4),\n",
    "                                       nn.Flatten(),\n",
    "                                       nn.Linear(512, num_diseases))\n",
    "        \n",
    "    def forward(self, x): # x is the loaded batch\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.classifier(out)\n",
    "        return out        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bcbcb61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=38, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model18 = torchvision.models.resnet18()\n",
    "num_ftrs = loaded_model18.fc.in_features\n",
    "loaded_model18.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "loaded_model18.load_state_dict(torch.load('data/resnet18/resnet18_model.pth'))\n",
    "# loaded_model = CNN_NeuralNet(3, len(class_names))\n",
    "# loaded_model.load_state_dict(torch.load('model.pth'))\n",
    "loaded_model18.to(device)\n",
    "loaded_model18.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b975f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=38, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model50 = torchvision.models.resnet50()\n",
    "num_ftrs = loaded_model50.fc.in_features\n",
    "loaded_model50.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "loaded_model50.load_state_dict(torch.load('data/resnet50/resnet50(2)_model.pth'))\n",
    "# loaded_model = CNN_NeuralNet(3, len(class_names))\n",
    "# loaded_model.load_state_dict(torch.load('model.pth'))\n",
    "loaded_model50.to(device)\n",
    "loaded_model50.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b4b6105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_NeuralNet(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (res1): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (res2): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=512, out_features=38, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loaded_model = torchvision.models.resnet18()\n",
    "# num_ftrs = loaded_model.fc.in_features\n",
    "# loaded_model.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "# loaded_model.load_state_dict(torch.load('data/resnet18/resnet18_model.pth'))\n",
    "loaded_model_custom = CNN_NeuralNet(3, len(class_names))\n",
    "loaded_model_custom.load_state_dict(torch.load('model.pth'))\n",
    "loaded_model_custom.to(device)\n",
    "loaded_model_custom.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78846260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img, model):\n",
    "    \"\"\"Converts image to array and return the predicted class\n",
    "        with highest probability\"\"\"\n",
    "    # Convert to a batch of 1\n",
    "    # xb = to_device(img.unsqueeze(0), device)\n",
    "    xb = img.unsqueeze(0).to(device)\n",
    "    # Get predictions from model\n",
    "    yb = model(xb)\n",
    "    # Pick index with highest probability\n",
    "    _, preds  = torch.max(yb, dim=1)\n",
    "    # Retrieve the class label\n",
    "\n",
    "    return preds[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7e2c990",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_acc = {}\n",
    "correct18 = 0\n",
    "correct50 = 0\n",
    "correct_custom = 0\n",
    "for i in range(len(test)):\n",
    "    img, label = test[i]\n",
    "    if predict_image(img, loaded_model18) == label:\n",
    "        correct18 += 1\n",
    "    if predict_image(img, loaded_model50) == label:\n",
    "        correct50 += 1\n",
    "    if predict_image(img, loaded_model_custom) == label:\n",
    "        correct_custom += 1\n",
    "\n",
    "all_acc[\"ResNet18\"] = (correct18/len(test))\n",
    "all_acc['ResNet50'] = (correct50/len(test))\n",
    "all_acc['Custom'] = (correct_custom/len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7c879d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResNet18': 0.041820768136557614, 'ResNet50': 0.02631578947368421, 'Custom': 0.99900426742532}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(all_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a63f458d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = []\n",
    "vals = []\n",
    "for k, v in all_acc.items():\n",
    "    labels.append(k)\n",
    "    vals.append(v*100)\n",
    "\n",
    "plt.bar(labels, vals)\n",
    "plt.title('Accuracy of models')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.show;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
