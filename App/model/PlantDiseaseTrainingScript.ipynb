{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T12:40:41.585324Z",
     "iopub.status.busy": "2025-04-08T12:40:41.584986Z",
     "iopub.status.idle": "2025-04-08T12:40:48.312502Z",
     "shell.execute_reply": "2025-04-08T12:40:48.311868Z",
     "shell.execute_reply.started": "2025-04-08T12:40:41.585293Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-08T12:40:48.313742Z",
     "iopub.status.busy": "2025-04-08T12:40:48.313257Z",
     "iopub.status.idle": "2025-04-08T12:40:48.331859Z",
     "shell.execute_reply": "2025-04-08T12:40:48.331177Z",
     "shell.execute_reply.started": "2025-04-08T12:40:48.313710Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Root_dir = \"D:/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)\"\n",
    "train_dir = Root_dir + \"/train\"\n",
    "valid_dir = Root_dir + \"/valid\"\n",
    "test_dir = \"D:/New Plant Diseases Dataset(Augmented)/test\"\n",
    "Diseases_classes = os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T12:40:48.332923Z",
     "iopub.status.busy": "2025-04-08T12:40:48.332615Z",
     "iopub.status.idle": "2025-04-08T12:40:48.338556Z",
     "shell.execute_reply": "2025-04-08T12:40:48.337773Z",
     "shell.execute_reply.started": "2025-04-08T12:40:48.332902Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nTotal number of classes are: \", len(Diseases_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images in each class, and sample of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T12:40:48.339508Z",
     "iopub.status.busy": "2025-04-08T12:40:48.339293Z",
     "iopub.status.idle": "2025-04-08T12:41:02.400882Z",
     "shell.execute_reply": "2025-04-08T12:41:02.399359Z",
     "shell.execute_reply.started": "2025-04-08T12:40:48.339480Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(60,60), dpi=200)\n",
    "cnt = 0\n",
    "plant_names = []\n",
    "tot_images = 0\n",
    "\n",
    "for i in Diseases_classes:\n",
    "    cnt += 1\n",
    "    plant_names.append(i)\n",
    "    plt.subplot(7,7,cnt)\n",
    "    \n",
    "    image_path = os.listdir(train_dir + \"/\" + i)\n",
    "    print(\"The Number of Images in \" +i+ \":\", len(image_path), end= \" \")\n",
    "    tot_images += len(image_path)\n",
    "    \n",
    "    img_show = plt.imread(train_dir + \"/\" + i + \"/\" + image_path[0])\n",
    "    \n",
    "    plt.imshow(img_show)\n",
    "    plt.xlabel(i,fontsize=30)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "print(\"\\nTotal Number of Images in Directory: \", tot_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the number of images in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T12:41:02.402522Z",
     "iopub.status.busy": "2025-04-08T12:41:02.402106Z",
     "iopub.status.idle": "2025-04-08T12:41:03.867926Z",
     "shell.execute_reply": "2025-04-08T12:41:03.867049Z",
     "shell.execute_reply.started": "2025-04-08T12:41:02.402481Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plant_names = []\n",
    "Len = []\n",
    "for i in Diseases_classes:\n",
    "    plant_names.append(i)\n",
    "    imgs_path = os.listdir(train_dir + \"/\" + i)\n",
    "    Len.append(len(imgs_path))\n",
    "\n",
    "Len.sort(reverse=True)\n",
    "\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "plt.figure(figsize=(20,20),dpi=200)\n",
    "ax = sns.barplot(x= Len, y= plant_names, palette=\"Greens\")\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch's Image Loader (for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T12:41:03.870181Z",
     "iopub.status.busy": "2025-04-08T12:41:03.869939Z",
     "iopub.status.idle": "2025-04-08T12:42:13.281323Z",
     "shell.execute_reply": "2025-04-08T12:42:13.280661Z",
     "shell.execute_reply.started": "2025-04-08T12:41:03.870160Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = ImageFolder(train_dir, transform=transforms.ToTensor())\n",
    "valid = ImageFolder(valid_dir, transform=transforms.ToTensor()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last Number represents the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T12:42:13.282961Z",
     "iopub.status.busy": "2025-04-08T12:42:13.282746Z",
     "iopub.status.idle": "2025-04-08T12:42:13.380690Z",
     "shell.execute_reply": "2025-04-08T12:42:13.380048Z",
     "shell.execute_reply.started": "2025-04-08T12:42:13.282944Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train\n",
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T12:42:13.381523Z",
     "iopub.status.busy": "2025-04-08T12:42:13.381338Z",
     "iopub.status.idle": "2025-04-08T12:42:13.391149Z",
     "shell.execute_reply": "2025-04-08T12:42:13.390502Z",
     "shell.execute_reply.started": "2025-04-08T12:42:13.381507Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train[7000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T12:42:13.392150Z",
     "iopub.status.busy": "2025-04-08T12:42:13.391868Z",
     "iopub.status.idle": "2025-04-08T12:42:13.408324Z",
     "shell.execute_reply": "2025-04-08T12:42:13.407613Z",
     "shell.execute_reply.started": "2025-04-08T12:42:13.392123Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train[70000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 (Number of Channels a.k.a. RGB) <br>\n",
    "256,256 (Size of picture) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T12:42:13.409516Z",
     "iopub.status.busy": "2025-04-08T12:42:13.409212Z",
     "iopub.status.idle": "2025-04-08T12:42:13.418662Z",
     "shell.execute_reply": "2025-04-08T12:42:13.417817Z",
     "shell.execute_reply.started": "2025-04-08T12:42:13.409488Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "img, label = train[0]\n",
    "print(img.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T12:42:13.419880Z",
     "iopub.status.busy": "2025-04-08T12:42:13.419475Z",
     "iopub.status.idle": "2025-04-08T12:42:15.862423Z",
     "shell.execute_reply": "2025-04-08T12:42:15.861625Z",
     "shell.execute_reply.started": "2025-04-08T12:42:13.419858Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def show_image(image, label):\n",
    "    print(\"Label :\" + train.classes[label] + \"(\" + str(label) + \")\")\n",
    "    plt.imshow(image.permute(1, 2, 0))\n",
    "    \n",
    "    \n",
    "image_list = [0, 3000, 5000, 8000, 12000, 15000, 60000, 70000]\n",
    "    \n",
    "chs = 0\n",
    "for img in image_list:\n",
    "    chs += 1\n",
    "    plt.subplot(2,4,chs)\n",
    "    plt.tight_layout()\n",
    "    plt.xlabel(img,fontsize=10)\n",
    "    plt.title(train[img][1])\n",
    "    show_image(*train[img])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T12:42:15.863832Z",
     "iopub.status.busy": "2025-04-08T12:42:15.863432Z",
     "iopub.status.idle": "2025-04-08T12:42:15.868768Z",
     "shell.execute_reply": "2025-04-08T12:42:15.867876Z",
     "shell.execute_reply.started": "2025-04-08T12:42:15.863799Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# DataLoaders for training and validation\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(train, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "valid_dataloader = DataLoader(valid, batch_size, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving training to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T12:42:15.869919Z",
     "iopub.status.busy": "2025-04-08T12:42:15.869596Z",
     "iopub.status.idle": "2025-04-08T12:42:15.881679Z",
     "shell.execute_reply": "2025-04-08T12:42:15.881013Z",
     "shell.execute_reply.started": "2025-04-08T12:42:15.869889Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available:\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dataloader, device):\n",
    "        self.dataloader = dataloader\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dataloader:\n",
    "            yield to_device(b, self.device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dataloader)\n",
    "\n",
    "device = get_default_device()\n",
    "device\n",
    "\n",
    "train_dataloader = DeviceDataLoader(train_dataloader, device)\n",
    "valid_dataloader = DeviceDataLoader(valid_dataloader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Base\n",
    "\n",
    "Let's create a step by step classification base module:\n",
    "\n",
    "First, Training_step: the images and labels take values from batch. The output of model is a type of images and the loss is calculate from F cross entropy function (out, labels). It seems that the prediction is compared with the actual values in labels.\n",
    "\n",
    "Second, validation step: is just like the above one. But it has another attribute call acc.\n",
    "\n",
    "Third, validation_epoch_end: calculate the losses and acces of each batchs and epochs.\n",
    "\n",
    "Fourth, epoch_end: That shows the final results of everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T12:42:15.882615Z",
     "iopub.status.busy": "2025-04-08T12:42:15.882328Z",
     "iopub.status.idle": "2025-04-08T12:42:15.892601Z",
     "shell.execute_reply": "2025-04-08T12:42:15.891953Z",
     "shell.execute_reply.started": "2025-04-08T12:42:15.882589Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# for calculating the accuracy\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T12:42:15.893647Z",
     "iopub.status.busy": "2025-04-08T12:42:15.893366Z",
     "iopub.status.idle": "2025-04-08T12:42:15.905987Z",
     "shell.execute_reply": "2025-04-08T12:42:15.905222Z",
     "shell.execute_reply.started": "2025-04-08T12:42:15.893616Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ImageClassificationBase(nn.Module):\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Block\n",
    "\n",
    "- Number of inputs\n",
    "- Outputs\n",
    "- Kernel Size\n",
    "- Padding\n",
    "- Batch Normalisation (WHY?)\n",
    "- Max Pooling (Blah Blah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T12:42:15.907047Z",
     "iopub.status.busy": "2025-04-08T12:42:15.906787Z",
     "iopub.status.idle": "2025-04-08T12:42:15.920560Z",
     "shell.execute_reply": "2025-04-08T12:42:15.919948Z",
     "shell.execute_reply.started": "2025-04-08T12:42:15.907028Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# convolution block with BatchNormalization\n",
    "def ConvBlock(in_channels, out_channels, pool=False):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "             nn.BatchNorm2d(out_channels),\n",
    "             nn.ReLU(inplace=True)]\n",
    "    if pool:\n",
    "        layers.append(nn.MaxPool2d(4))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n",
    "We use the class of ImageClassificationBase for taking methods like calculating the loss and acc of epochs. And after that, we set our layers. We use more layers but in this case, the size of images don't allow to do that Going to be zero. In the second part, we connect layers to each other. The output of layer number N, is the input of layer number N+1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T12:42:15.921578Z",
     "iopub.status.busy": "2025-04-08T12:42:15.921288Z",
     "iopub.status.idle": "2025-04-08T12:42:15.932777Z",
     "shell.execute_reply": "2025-04-08T12:42:15.931958Z",
     "shell.execute_reply.started": "2025-04-08T12:42:15.921550Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# resnet architecture \n",
    "class CNN_NeuralNet(ImageClassificationBase):\n",
    "    def __init__(self, in_channels, num_diseases):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = ConvBlock(in_channels, 64)\n",
    "        self.conv2 = ConvBlock(64, 128, pool=True) \n",
    "        self.res1 = nn.Sequential(ConvBlock(128, 128), ConvBlock(128, 128))\n",
    "        \n",
    "        self.conv3 = ConvBlock(128, 256, pool=True) \n",
    "        self.conv4 = ConvBlock(256, 512, pool=True)\n",
    "        #self.conv5 = ConvBlock(256, 256, pool=True)\n",
    "        #self.conv6 = ConvBlock(256, 512, pool=True)\n",
    "        #self.conv7 = ConvBlock(512, 512, pool=True)\n",
    "        \n",
    "        self.res2 = nn.Sequential(ConvBlock(512, 512), ConvBlock(512, 512))\n",
    "        self.classifier = nn.Sequential(nn.MaxPool2d(4),\n",
    "                                       nn.Flatten(),\n",
    "                                       nn.Linear(512, num_diseases))\n",
    "        \n",
    "    def forward(self, x): # x is the loaded batch\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        #out = self.conv5(out)\n",
    "        #out = self.conv6(out)\n",
    "        #out = self.conv7(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.classifier(out)\n",
    "        return out        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Connecting the model to use a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T12:42:15.933797Z",
     "iopub.status.busy": "2025-04-08T12:42:15.933517Z",
     "iopub.status.idle": "2025-04-08T12:42:16.292285Z",
     "shell.execute_reply": "2025-04-08T12:42:16.291380Z",
     "shell.execute_reply.started": "2025-04-08T12:42:15.933771Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# defining the model and moving it to the GPU\n",
    "# 3 is number of channels RGB, len(train.classes()) is number of diseases.\n",
    "model = to_device(CNN_NeuralNet(3, len(train.classes)), device) \n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Eval / Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T12:42:16.293517Z",
     "iopub.status.busy": "2025-04-08T12:42:16.293196Z",
     "iopub.status.idle": "2025-04-08T12:42:16.297544Z",
     "shell.execute_reply": "2025-04-08T12:42:16.296679Z",
     "shell.execute_reply.started": "2025-04-08T12:42:16.293484Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# for training\n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T12:42:16.300967Z",
     "iopub.status.busy": "2025-04-08T12:42:16.300762Z",
     "iopub.status.idle": "2025-04-08T12:42:16.312233Z",
     "shell.execute_reply": "2025-04-08T12:42:16.311550Z",
     "shell.execute_reply.started": "2025-04-08T12:42:16.300950Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T12:42:16.313769Z",
     "iopub.status.busy": "2025-04-08T12:42:16.313466Z",
     "iopub.status.idle": "2025-04-08T12:42:16.326668Z",
     "shell.execute_reply": "2025-04-08T12:42:16.326041Z",
     "shell.execute_reply.started": "2025-04-08T12:42:16.313740Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def fit_OneCycle(epochs, max_lr, model, train_loader, val_loader, weight_decay=0,\n",
    "                grad_clip=None, opt_func=torch.optim.SGD):\n",
    "    torch.cuda.empty_cache()\n",
    "    history = []  #For collecting the results\n",
    "    \n",
    "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "    # scheduler for one cycle learniing rate\n",
    "    #Sets the learning rate of each parameter group according to the 1cycle learning rate policy. \n",
    "    #The 1cycle policy anneals the learning rate from an initial learning rate to some \n",
    "    #maximum learning rate and then from that maximum learning rate to some minimum learning rate\n",
    "    #much lower than the initial learning rate. \n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr,\n",
    "                                                epochs=epochs, steps_per_epoch=len(train_loader))\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        lrs = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            \n",
    "            # gradient clipping\n",
    "            #Clip the gradients of an iterable of parameters at specified value.\n",
    "            #All from pytorch documantation.\n",
    "            if grad_clip: \n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "                \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # recording and updating learning rates\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            sched.step()\n",
    "             # validation\n",
    "        \n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        result['lrs'] = lrs\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "        \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-08T13:47:12.684Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history = [evaluate(model, valid_dataloader)]\n",
    "history\n",
    "\n",
    "num_epoch = 5\n",
    "lr_rate = 0.01\n",
    "grad_clip = 0.15\n",
    "weight_decay = 1e-4\n",
    "optims = torch.optim.Adam\n",
    "\n",
    "history += fit_OneCycle(num_epoch, lr_rate, model, train_dataloader, valid_dataloader, \n",
    "                             grad_clip=grad_clip, \n",
    "                             weight_decay=weight_decay, \n",
    "                             opt_func=optims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"data\\custom_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-08T13:47:12.685Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "val_acc = []\n",
    "val_loss = []\n",
    "train_loss = []\n",
    "\n",
    "for i in history:\n",
    "    val_acc.append(i['val_acc'])\n",
    "    val_loss.append(i['val_loss'])\n",
    "    train_loss.append(i.get('train_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-08T13:47:12.685Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "epoch_count = range(1,7)\n",
    "plt.figure(figsize=(10,5), dpi=200)\n",
    "plt.plot(epoch_count, train_loss, 'r--', color= 'orangered')\n",
    "plt.plot(epoch_count, val_loss, '--bo',color= 'green', linewidth = '2.5', label='line with marker')\n",
    "plt.legend(['Training Loss', 'Val Loss'])\n",
    "plt.title('Number of epochs & Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.xticks(np.arange(1,7,1))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-08T13:47:12.685Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "epoch_count = range(1,7)\n",
    "plt.figure(figsize=(10,5), dpi=200)\n",
    "plt.plot(epoch_count, val_acc, '--bo',color= 'green', linewidth = '2.5', label='line with marker')\n",
    "plt.legend(['Val Acc'])\n",
    "plt.title('Number of epochs & Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Acc')\n",
    "plt.xticks(np.arange(1,7,1))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-08T13:47:12.684Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test = ImageFolder(test_dir, transform=transforms.ToTensor())\n",
    "test_images = sorted(os.listdir(test_dir + '/test'))\n",
    "print(test_images)\n",
    "print(len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-08T13:47:12.684Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict_image(img, model):\n",
    "    \"\"\"Converts image to array and return the predicted class\n",
    "        with highest probability\"\"\"\n",
    "    # Convert to a batch of 1\n",
    "    xb = to_device(img.unsqueeze(0), device)\n",
    "    # Get predictions from model\n",
    "    yb = model(xb)\n",
    "    # Pick index with highest probability\n",
    "    _, preds  = torch.max(yb, dim=1)\n",
    "    # Retrieve the class label\n",
    "\n",
    "    return train.classes[preds[0].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-08T13:47:12.684Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "wrong = 0\n",
    "for i in range(test_images):\n",
    "    print(len(test_images))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 78313,
     "sourceId": 182633,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
